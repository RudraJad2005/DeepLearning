{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af57816",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction to Deep Learning with PyTorch\n",
    "\n",
    "## 1. What is PyTorch?\n",
    "PyTorch is an open-source machine learning library developed by Facebook's AI Research lab. It provides:\n",
    "- Tensor computation (like NumPy) with strong GPU acceleration\n",
    "- Deep neural networks built on a tape-based autograd system\n",
    "- Easy-to-use API for building and training neural networks\n",
    "\n",
    "## 2. Tensors: The Building Blocks\n",
    "**Tensors** are multi-dimensional arrays that store data. They are the fundamental data structure in PyTorch.\n",
    "\n",
    "### Creating Tensors\n",
    "- Use `torch.tensor()` to create a tensor from a Python list\n",
    "- Tensors can be 1D (vector), 2D (matrix), or higher dimensional\n",
    "\n",
    "### Example:\n",
    "```python\n",
    "temperature = [[43, 45, 21], [65, 87, 98]]\n",
    "temp_tensor = torch.tensor(temperature)\n",
    "```\n",
    "This creates a 2D tensor (2 rows, 3 columns)\n",
    "\n",
    "## 3. Tensor Operations\n",
    "PyTorch supports element-wise operations on tensors:\n",
    "- **Addition**: `tensor1 + tensor2`\n",
    "- **Subtraction**: `tensor1 - tensor2`\n",
    "- **Multiplication**: `tensor1 * tensor2`\n",
    "- **Division**: `tensor1 / tensor2`\n",
    "\n",
    "**Note**: Tensors must have compatible shapes for operations\n",
    "\n",
    "## 4. Neural Network Basics\n",
    "\n",
    "### 4.1 Linear Layer (nn.Linear)\n",
    "A **Linear Layer** performs a linear transformation: `y = xW^T + b`\n",
    "- `W` = weight matrix\n",
    "- `b` = bias vector\n",
    "- `x` = input tensor\n",
    "\n",
    "**Syntax**: `nn.Linear(in_features, out_features)`\n",
    "- `in_features`: size of input\n",
    "- `out_features`: size of output\n",
    "\n",
    "### Example:\n",
    "```python\n",
    "linear_layer = nn.Linear(in_features=3, out_features=2)\n",
    "```\n",
    "This layer takes 3 inputs and produces 2 outputs\n",
    "\n",
    "### 4.2 Sequential Models\n",
    "`nn.Sequential` allows you to stack multiple layers to create a neural network.\n",
    "\n",
    "```python\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 4),  # Input: 8, Output: 4\n",
    "    nn.Linear(4, 1)   # Input: 4, Output: 1\n",
    ")\n",
    "```\n",
    "\n",
    "## 5. Model Parameters\n",
    "Every neural network layer has **parameters** (weights and biases) that are learned during training.\n",
    "\n",
    "### Counting Parameters\n",
    "Use `.parameters()` to iterate through all parameters:\n",
    "```python\n",
    "total = 0\n",
    "for p in model.parameters():\n",
    "    total += p.numel()  # numel() returns number of elements\n",
    "```\n",
    "\n",
    "### Parameter Calculation:\n",
    "For a Linear layer with `in_features=m` and `out_features=n`:\n",
    "- **Weights**: `m × n` parameters\n",
    "- **Bias**: `n` parameters\n",
    "- **Total**: `(m × n) + n = n(m + 1)` parameters\n",
    "\n",
    "### Example Calculation:\n",
    "```\n",
    "Layer 1: nn.Linear(8, 4) → 8×4 + 4 = 36 parameters\n",
    "Layer 2: nn.Linear(4, 1) → 4×1 + 1 = 5 parameters\n",
    "Total: 36 + 5 = 41 parameters\n",
    "```\n",
    "\n",
    "## 6. Key Concepts Summary\n",
    "1. **Tensors** are the core data structure in PyTorch\n",
    "2. **nn.Linear** creates fully connected layers\n",
    "3. **nn.Sequential** chains layers together\n",
    "4. **Parameters** are the learnable weights in the network\n",
    "5. PyTorch uses **dynamic computation graphs** (define-by-run)\n",
    "\n",
    "## 7. Important Methods\n",
    "- `torch.tensor()`: Create a tensor\n",
    "- `torch.Tensor()`: Create a tensor (alternative constructor)\n",
    "- `.numel()`: Count elements in a tensor\n",
    "- `.parameters()`: Access model parameters\n",
    "- `nn.Linear()`: Create a linear transformation layer\n",
    "- `nn.Sequential()`: Stack layers sequentially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c343be62",
   "metadata": {},
   "source": [
    "## Example 1: Creating and Manipulating Tensors\n",
    "\n",
    "This example demonstrates:\n",
    "- **Creating tensors from Python lists** using `torch.tensor()`\n",
    "- **Tensor addition** - Adding two tensors element-wise\n",
    "- **Output**: Shows the original tensor and the result of addition\n",
    "\n",
    "**Key Learning**: Tensors can perform vectorized operations, which are much faster than regular Python loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea19dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[43, 45, 21],\n",
      "        [65, 87, 98]])\n",
      "tensor([[ 45,  47,  24],\n",
      "        [ 67,  91, 103]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "temperature = [[43, 45, 21], [65, 87, 98]]\n",
    "\n",
    "temp_tensor = torch.tensor(temperature)\n",
    "print(temp_tensor)\n",
    "\n",
    "adjusted_temp = torch.tensor([[2, 2, 3], [2, 4, 5]])\n",
    "\n",
    "addition_result = temp_tensor + adjusted_temp\n",
    "print(addition_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12bbee7",
   "metadata": {},
   "source": [
    "## Example 2: Linear Layer Transformation\n",
    "\n",
    "This example shows:\n",
    "- **Creating a linear layer** with `nn.Linear(in_features=3, out_features=2)`\n",
    "- **Input tensor**: 1 sample with 3 features\n",
    "- **Output tensor**: 1 sample with 2 features (transformed)\n",
    "- The layer applies the formula: `output = input × W^T + b`\n",
    "\n",
    "**Key Learning**: Linear layers are the building blocks of neural networks. They transform data from one dimension to another using learnable weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb78244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1064, -0.3833]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([[0.3471, 0.4547, -0.2356]])\n",
    "\n",
    "linear_Layer = nn.Linear(in_features=3, out_features=2)\n",
    "\n",
    "output = linear_Layer(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520189d",
   "metadata": {},
   "source": [
    "## Example 3: Building a Multi-Layer Neural Network\n",
    "\n",
    "This example demonstrates:\n",
    "- **Creating a sequential model** with multiple layers\n",
    "- **First layer**: Transforms 8 inputs → 4 outputs\n",
    "- **Second layer**: Transforms 4 inputs → 1 output\n",
    "- **nn.Sequential**: Automatically connects layers so output of one layer feeds into the next\n",
    "\n",
    "**Key Learning**: Deep neural networks are created by stacking multiple layers. Data flows through each layer sequentially, getting transformed at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea9fe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9243]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# My First Neural Network\n",
    "\n",
    "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 4),\n",
    "    nn.Linear(4, 1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af03398",
   "metadata": {},
   "source": [
    "## Example 4: Counting Model Parameters\n",
    "\n",
    "This example shows:\n",
    "- **Iterating through parameters** using `model.parameters()`\n",
    "- **Counting elements** with `.numel()` (number of elements)\n",
    "- **Total parameters**: Sum of all weights and biases in the model\n",
    "\n",
    "**Calculation breakdown**:\n",
    "- Layer 1 (8→4): (8×4) + 4 = 36 parameters\n",
    "- Layer 2 (4→1): (4×1) + 1 = 5 parameters\n",
    "- **Total**: 41 parameters\n",
    "\n",
    "**Key Learning**: Understanding parameter count helps you estimate model size, memory requirements, and training complexity. More parameters = more capacity to learn, but also more risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f79f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 41\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of parameters in the model\n",
    "\n",
    "total = 0\n",
    "\n",
    "for p in model.parameters():\n",
    "\n",
    "    total += p.numel()\n",
    "\n",
    "print(f'Total number of parameters in the model: {total}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
