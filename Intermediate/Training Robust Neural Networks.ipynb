{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "954d74af",
   "metadata": {},
   "source": [
    "# Training Robust Neural Networks — Notes\n",
    "\n",
    "## Notebook Overview\n",
    "- Goal: Binary classification of water potability with a small feedforward neural network in PyTorch, trained and evaluated with accuracy.\n",
    "- Data: Custom `WaterDataset` reads CSVs, features are last column excluded, label is last column.\n",
    "\n",
    "## Cell-by-Cell Notes\n",
    "- **Cell 1 — Imports:** Loads `pandas`, `torch`, `Dataset`, `DataLoader`, `nn`, `optim`, and `torchmetrics.Accuracy` for data, modeling, optimization, and evaluation.\n",
    "- **Cell 2 — `WaterDataset`:** Reads CSV to NumPy; returns `torch.Tensor` features/labels (`float32`). Label reshaped later with `view(-1, 1)` to match model output.\n",
    "- **Cell 3 — Train DataLoader + Preview:** Wraps the dataset (`batch_size=2`, `shuffle=True`); prints a sample batch to verify shapes/dtypes.\n",
    "- **Cell 4 — `Net` model:** `fc1(9→16)` → ReLU → `fc2(16→8)` → ReLU → `fc(8→1)` → Sigmoid to output a probability for binary classification.\n",
    "- **Cell 5 — Training:** `train_model(...)` runs a standard loop with `BCELoss`. Casts tensors to float, reshapes labels to `(-1, 1)`, and uses `SGD(lr=0.001)`. Prints epoch progress.\n",
    "- **Cell 6 — Evaluation:** Builds test `DataLoader`, sets `net.eval()`, uses `torch.no_grad()`, thresholds predictions at 0.5, computes `Accuracy(task=\"binary\")`, prints final accuracy.\n",
    "\n",
    "## Key Flow\n",
    "- CSV → `WaterDataset` → `DataLoader` (train/test) → model → train with BCE → evaluate with accuracy.\n",
    "\n",
    "## Pitfalls Avoided\n",
    "- Dtype/shape mismatches: Explicit `.float()` casts and `labels.view(-1, 1)` ensure `BCELoss` matches model output.\n",
    "- Correct modes: `net.eval()` and `torch.no_grad()` for evaluation to disable gradients.\n",
    "\n",
    "## Recommended Improvements\n",
    "- Numerical stability: Prefer `BCEWithLogitsLoss` and remove model `sigmoid`; threshold logits with `torch.sigmoid` in eval.\n",
    "- Feature scaling: Normalize/standardize inputs to improve convergence.\n",
    "- Optimizer/params: Try `Adam(lr=1e-3)`, tune `batch_size` (e.g., 32) and `num_epochs`.\n",
    "- Metrics: Add precision/recall/F1 if class imbalance exists (`torchmetrics`).\n",
    "- Reproducibility: Set seeds for `torch` and `numpy`; control `DataLoader` randomness.\n",
    "\n",
    "## Run Order\n",
    "1. Imports\n",
    "2. Dataset\n",
    "3. Train DataLoader (preview)\n",
    "4. Model\n",
    "5. Training\n",
    "6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c07061eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed271147",
   "metadata": {},
   "source": [
    "### Notes — Imports\n",
    "- pandas: CSV loading and data manipulation.\n",
    "- torch: Core tensor and autograd library.\n",
    "- torch.utils.data `Dataset`, `DataLoader`: Custom dataset wrapper and batch iteration.\n",
    "- torch.nn, torch.nn.functional: Neural network layers and functional activations (ReLU, Sigmoid).\n",
    "- torch.optim: Optimizers (SGD, Adam) for parameter updates.\n",
    "- torchmetrics `Accuracy(task=\"binary\")`: Computes binary classification accuracy from predictions and targets.\n",
    "\n",
    "Run this cell first to make all symbols available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8541a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        super().__init__()\n",
    "\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.data = df.to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = self.data[idx, :-1].astype('float32')\n",
    "        labels = self.data[idx, -1].astype('float32')\n",
    "        return torch.from_numpy(features), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f6e4b",
   "metadata": {},
   "source": [
    "### Notes — WaterDataset\n",
    "- Reads a CSV into a NumPy array and stores it in `self.data`.\n",
    "- `__len__`: returns number of rows.\n",
    "- `__getitem__`: splits features (all columns except last) and label (last column).\n",
    "- Casts to `float32` and returns PyTorch tensors for seamless training.\n",
    "- Label is a scalar; later reshaped to `(-1, 1)` to match model output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dff8032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2634, 0.2375, 0.3439, 0.5421, 0.5010, 0.4620, 0.5912, 0.6320, 0.5630],\n",
      "        [0.7376, 0.5225, 0.3144, 0.3796, 0.5965, 0.2441, 0.4886, 0.4642, 0.6881]]) tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the WaterDataset\n",
    "\n",
    "dataset_train = WaterDataset(csv_file='./water_potability/water_train.csv')\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size = 2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "features, labels = next(iter(data_loader_train))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d2796",
   "metadata": {},
   "source": [
    "### Notes — Train DataLoader & Preview\n",
    "- Wraps the training dataset in a `DataLoader` with `batch_size=2` and `shuffle=True` for stochastic minibatches.\n",
    "- The preview (`next(iter(...))`) quickly checks shapes/dtypes of a sample batch.\n",
    "- Ensure features are tensors of shape `[batch, 9]` and labels are `[batch]` (reshaped later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "323023f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(9, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc = nn.Linear(8, 1)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4ae2ef",
   "metadata": {},
   "source": [
    "### Notes — Model (`Net`)\n",
    "- Architecture: `fc1(9→16)` → ReLU → `fc2(16→8)` → ReLU → `fc(8→1)` → Sigmoid.\n",
    "- Final Sigmoid outputs a probability for binary classification.\n",
    "- Pairing with `BCELoss` is consistent; alternatively remove Sigmoid and use `BCEWithLogitsLoss` for better numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db72c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 completed\n",
      "Epoch 2/10 completed\n",
      "Epoch 3/10 completed\n",
      "Epoch 4/10 completed\n",
      "Epoch 5/10 completed\n",
      "Epoch 6/10 completed\n",
      "Epoch 7/10 completed\n",
      "Epoch 8/10 completed\n",
      "Epoch 9/10 completed\n",
      "Epoch 10/10 completed\n"
     ]
    }
   ],
   "source": [
    "# Training Loop.\n",
    "\n",
    "# for epoch in range(1000):\n",
    "#     for features, labels in data_loader_train:\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = criterion(net(features), labels.view(-1, 1)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "def train_model(optimizer, net, num_epochs, criterion=None, data_loader=None):\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    data_loader = data_loader_train\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for features, labels in data_loader:\n",
    "            features = features.float()\n",
    "            labels = labels.float()\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(features), labels.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} completed\")\n",
    "        \n",
    "###### Optimizers ######\n",
    "net = Net()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "train_model(\n",
    "    optimizer=optimizer,\n",
    "    net=net,\n",
    "    num_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab18e79b",
   "metadata": {},
   "source": [
    "### Notes — Training Loop\n",
    "- `train_model(...)`: Standard epoch/batch loop.\n",
    "- Loss: `BCELoss` expects probabilities; model applies Sigmoid.\n",
    "- Casting: `features.float()` and `labels.float()` avoid dtype issues.\n",
    "- Shape: `labels.view(-1, 1)` matches model output shape `[batch, 1]`.\n",
    "- Optimizer: SGD with learning rate `0.001` updates parameters each step.\n",
    "- Prints epoch completion for progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7def37b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5904572606086731\n"
     ]
    }
   ],
   "source": [
    "dataset_test = WaterDataset(csv_file='./water_potability/water_test.csv')\n",
    "\n",
    "data_loader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size = 2,\n",
    "    shuffle=True\n",
    ")\n",
    "# Ignore above code (its just for context)\n",
    "########### Model evaluation ###########\n",
    "acc = Accuracy(task=\"binary\")\n",
    "\n",
    "net.eval()  \n",
    "with torch.no_grad():\n",
    "    for features, labels in data_loader_test:\n",
    "\n",
    "        output = net(features)\n",
    "        preds = (output > 0.5).float()\n",
    "        acc(preds, labels.view(-1, 1))\n",
    "\n",
    "test_accuracy = acc.compute()\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90839054",
   "metadata": {},
   "source": [
    "### Notes — Evaluation\n",
    "- Test `DataLoader` mirrors training setup.\n",
    "- `net.eval()` + `torch.no_grad()` disable dropout (if any) and gradient tracking.\n",
    "- Forward pass: `output` is probability; threshold at `0.5` to get binary predictions.\n",
    "- Metric: `Accuracy(task=\"binary\")` computes final accuracy; `acc.compute()` returns a scalar.\n",
    "- Prints test accuracy for quick performance assessment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
